{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chest X-ray Image Report Generation (CXIRG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install Required Modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: openpyxl in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (3.1.2)\n",
                        "Requirement already satisfied: et-xmlfile in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
                        "Requirement already satisfied: pandas in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (2.2.2)\n",
                        "Requirement already satisfied: numpy>=1.22.4 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: six>=1.5 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
                        "Requirement already satisfied: pillow in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (10.3.0)\n",
                        "Requirement already satisfied: pytorch-ignite in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (0.5.0.post2)\n",
                        "Requirement already satisfied: torch<3,>=1.3 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pytorch-ignite) (2.3.0)\n",
                        "Requirement already satisfied: packaging in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from pytorch-ignite) (24.0)\n",
                        "Requirement already satisfied: filelock in /home/pulsar/.local/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.12.4)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (4.11.0)\n",
                        "Requirement already satisfied: sympy in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
                        "Requirement already satisfied: networkx in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.3)\n",
                        "Requirement already satisfied: jinja2 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n",
                        "Requirement already satisfied: fsspec in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2024.5.0)\n",
                        "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (8.9.2.26)\n",
                        "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.3.1)\n",
                        "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.0.2.54)\n",
                        "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (10.3.2.106)\n",
                        "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (11.4.5.107)\n",
                        "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.0.106)\n",
                        "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.20.5)\n",
                        "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (12.1.105)\n",
                        "Requirement already satisfied: triton==2.3.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch<3,>=1.3->pytorch-ignite) (2.3.0)\n",
                        "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3,>=1.3->pytorch-ignite) (12.4.127)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.5)\n",
                        "Requirement already satisfied: mpmath>=0.19 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
                        "Requirement already satisfied: scikit-learn in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (1.4.2)\n",
                        "Requirement already satisfied: numpy>=1.19.5 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
                        "Requirement already satisfied: scipy>=1.6.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
                        "Requirement already satisfied: torch in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (2.3.0)\n",
                        "Requirement already satisfied: filelock in /home/pulsar/.local/lib/python3.10/site-packages (from torch) (3.12.4)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (4.11.0)\n",
                        "Requirement already satisfied: sympy in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (1.12)\n",
                        "Requirement already satisfied: networkx in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (3.3)\n",
                        "Requirement already satisfied: jinja2 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (3.1.4)\n",
                        "Requirement already satisfied: fsspec in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (2024.5.0)\n",
                        "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.105)\n",
                        "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
                        "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
                        "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
                        "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
                        "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
                        "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
                        "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (2.20.5)\n",
                        "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (12.1.105)\n",
                        "Requirement already satisfied: triton==2.3.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from torch) (2.3.0)\n",
                        "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
                        "Requirement already satisfied: mpmath>=0.19 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
                        "Requirement already satisfied: transformers in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (4.41.0)\n",
                        "Requirement already satisfied: filelock in /home/pulsar/.local/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
                        "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
                        "Requirement already satisfied: numpy>=1.17 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
                        "Requirement already satisfied: packaging>=20.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (24.0)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
                        "Requirement already satisfied: regex!=2019.12.17 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
                        "Requirement already satisfied: requests in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (2.32.1)\n",
                        "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
                        "Requirement already satisfied: safetensors>=0.4.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
                        "Requirement already satisfied: tqdm>=4.27 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
                        "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
                    ]
                }
            ],
            "source": [
                "!pip install openpyxl\n",
                "!pip install pandas\n",
                "!pip install pillow\n",
                "!pip install pytorch-ignite\n",
                "!pip install scikit-learn\n",
                "!pip install torch\n",
                "!pip install transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Required Modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import random\n",
                "import torch\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from ignite.metrics import Rouge\n",
                "from pandas.core.common import random_state\n",
                "from PIL import Image\n",
                "from sklearn.model_selection import train_test_split\n",
                "from torch.optim import AdamW\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from tqdm import tqdm\n",
                "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer, ViTModel, ViTImageProcessor\n",
                "from typing import Any, Dict, List, Tuple"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Random Seed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = 48763\n",
                "\n",
                "np.random.seed(seed=seed, )\n",
                "\n",
                "random_state(state=seed, )\n",
                "\n",
                "random.seed(a=seed, )\n",
                "\n",
                "torch.manual_seed(seed=seed, )\n",
                "torch.cuda.manual_seed(seed=seed, )\n",
                "torch.cuda.manual_seed_all(seed=seed, )\n",
                "torch.backends.cudnn.benchmark = False\n",
                "torch.backends.cudnn.deterministic = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Device & Initialize Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/pulsar/miniconda3/envs/GAI/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
                        "  warnings.warn(\n",
                        "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                        "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                }
            ],
            "source": [
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "# Language Model\n",
                "lm_config = GPT2Config.from_pretrained(\"gpt2\")\n",
                "lm_config.add_cross_attention = True\n",
                "lm = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=lm_config).to(device)\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
                "tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "# Vision Model\n",
                "vm = ViTModel.from_pretrained(\"google/vit-base-patch16-224\").to(device)\n",
                "for param in vm.parameters():\n",
                "    param.requires_grad = False\n",
                "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The CXIRG Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CXIRGDataset(Dataset):\n",
                "    def __init__(self, data: List[Dict[str, Any]]) -> None:\n",
                "        super(CXIRGDataset, self).__init__()\n",
                "        self.data = data\n",
                "\n",
                "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
                "        return self.data[index]\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Collate Function for The DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = \"Please generate a report based on the given chest X-ray image.\"\n",
                "\n",
                "def collate_fn(one_batch_data: List[Dict[str, Any]]):\n",
                "    names = [one_data[\"name\"] for one_data in one_batch_data]\n",
                "\n",
                "    images_middle = processor(\n",
                "        images=[one_data[\"image\"] for one_data in one_batch_data], \n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "    images_middle = images_middle.to(device)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        images_embedding = vm(**images_middle).last_hidden_state\n",
                "\n",
                "    max_length = max([len(one_data[\"text\"]) for one_data in one_batch_data])\n",
                "    max_length = min(max_length, 1024)\n",
                "\n",
                "    inputs_token = tokenizer.batch_encode_plus(\n",
                "        batch_text_or_text_pairs=[\n",
                "            (prompt + \" \" + tokenizer.eos_token + \" \" + one_data[\"text\"]) for one_data in one_batch_data\n",
                "        ],\n",
                "        max_length=max_length,\n",
                "        padding=True,\n",
                "        truncation=True,\n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "    attention_mask = inputs_token[\"attention_mask\"]\n",
                "    inputs_token = inputs_token[\"input_ids\"]\n",
                "\n",
                "    labels_token = inputs_token.clone()\n",
                "    for idx, one_data in enumerate(one_batch_data):\n",
                "        text_length = (len(tokenizer(prompt)[\"input_ids\"]) + 1)\n",
                "        labels_token[idx, :text_length] = -100\n",
                "\n",
                "    return names, images_embedding.to(device), inputs_token.to(device), labels_token.to(device), attention_mask.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load The Train & Validation Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = []\n",
                "\n",
                "report_path = \"data/train_data/reports.xlsx\"\n",
                "report_df = pd.read_excel(report_path)\n",
                "\n",
                "image_dir_path = \"data/train_data/images\"\n",
                "for image_name in os.listdir(image_dir_path):\n",
                "    image = Image.open(os.path.join(image_dir_path, image_name))\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "\n",
                "    text = report_df[report_df[\"name\"] == image_name[:13]][\"text\"].values[0].replace(\"_x000D_\", \"\\r\")\n",
                "\n",
                "    train_data.append({\n",
                "        \"name\": image_name[:13],\n",
                "        \"image\": image,\n",
                "        \"text\": text\n",
                "    })\n",
                "\n",
                "train_dataset = CXIRGDataset(train_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "valid_data = []\n",
                "\n",
                "report_path = \"data/valid_data/reports.xlsx\"\n",
                "report_df = pd.read_excel(report_path)\n",
                "\n",
                "image_dir_path = \"data/valid_data/images\"\n",
                "for image_name in os.listdir(image_dir_path):\n",
                "    image = Image.open(os.path.join(image_dir_path, image_name))\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "\n",
                "    text = report_df[report_df[\"name\"] == image_name[:13]][\"text\"].values[0].replace(\"_x000D_\", \"\\r\")\n",
                "\n",
                "    valid_data.append({\n",
                "        \"name\": image_name[:13],\n",
                "        \"image\": image,\n",
                "        \"text\": text\n",
                "    })\n",
                "\n",
                "valid_dataset = CXIRGDataset(valid_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Hyperparameters & Initialize The Optimizer, Dataloaders and Evaluation Metric"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = 1e-5\n",
                "epochs = 1\n",
                "optimizer = AdamW(params=lm.parameters(), lr=lr)\n",
                "\n",
                "train_batch_size = 8\n",
                "valid_batch_size = 1\n",
                "train_dataloader = DataLoader(\n",
                "    dataset=train_dataset,\n",
                "    batch_size=train_batch_size,\n",
                "    shuffle=True,\n",
                "    collate_fn=collate_fn\n",
                ")\n",
                "valid_dataloader = DataLoader(\n",
                "    dataset=valid_dataset,\n",
                "    batch_size=valid_batch_size,\n",
                "    shuffle=False,\n",
                "    collate_fn=collate_fn\n",
                ")\n",
                "\n",
                "rouge = Rouge(variants=[\"L\", 2], multiref=\"best\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Evaluation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate(lm: GPT2LMHeadModel, epoch: int) -> Tuple[Dict[str, float], float]:\n",
                "    lm.eval()\n",
                "\n",
                "    pbar = tqdm(valid_dataloader)\n",
                "    pbar.set_description(f\"Evaluting Epoch: {epoch + 1}\")\n",
                "\n",
                "    loss_list = []\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for names, images, inputs, labels, attention_mask in pbar:\n",
                "            loss = lm(\n",
                "                input_ids=inputs,\n",
                "                attention_mask=attention_mask,\n",
                "                encoder_hidden_states=images,\n",
                "                labels=labels\n",
                "            ).loss\n",
                "            loss_list.append(loss.item())\n",
                "            pbar.set_postfix(loss=loss.item())\n",
                "\n",
                "            predictions_inputs = {\n",
                "                \"input_ids\": inputs,\n",
                "                \"attention_mask\": attention_mask,\n",
                "                \"encoder_hidden_states\": images\n",
                "            }\n",
                "\n",
                "            predictions = [\n",
                "                prediction for prediction in tokenizer.batch_decode(\n",
                "                    lm.generate(\n",
                "                        **predictions_inputs,\n",
                "                        max_length=256\n",
                "                    )\n",
                "                )\n",
                "            ]\n",
                "\n",
                "            prompt_token = tokenizer.encode(\n",
                "                text=prompt,\n",
                "                return_tensors=\"pt\"\n",
                "            ).to(device).squeeze(0)\n",
                "\n",
                "            _labels = []\n",
                "            for _label in labels:\n",
                "                _label = torch.cat((prompt_token, _label), 0)\n",
                "                _label = _label.tolist()\n",
                "                _label = [token for token in _label if token != -100]\n",
                "                _labels.append(tokenizer.batch_decode([_label])[0])\n",
                "\n",
                "            print(f\"Names: {names}\")\n",
                "            print(f\"Predictions: {predictions}\")\n",
                "            print(f\"Labels: {_labels}\")\n",
                "            print()\n",
                "\n",
                "            for prediction, _label in zip(predictions, _labels):\n",
                "                split_prediction = prediction.split()\n",
                "                split_label = _label.split()\n",
                "\n",
                "                for one_word in split_prediction:\n",
                "                    rouge.update(([one_word], [split_label]))\n",
                "\n",
                "    return rouge.compute(), np.mean(np.array(loss_list))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Training Epoch [1 / 1]: 100%|██████████| 12/12 [00:05<00:00,  2.04it/s, loss=5.21]\n",
                        "Evaluting Epoch: 1:   0%|          | 0/10 [00:00<?, ?it/s, loss=4.89]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  10%|█         | 1/10 [00:00<00:02,  4.12it/s, loss=5.81]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  20%|██        | 2/10 [00:00<00:01,  5.77it/s, loss=5.81]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_071']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest film shows:\\r\\nImpression:\\r\\n-Bilateral lung infiltrations.\\r\\n-Suspect right lower lung patch. \\r\\n Blunting right CP angle. \\r\\n-Tortuous atherosclerotic aorta. \\r\\n-Scoliosis, DJD and osteoporosis of spine. \\r\\n Compression fracture of T12.\\r\\n Old fracture of left ribs.\\r\\n-S/P fixation in L-spine.  \\r\\n-S/P tracheostomy and NG tube.   \\r\\n-S/P tracheostomy and NG tube.   <|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest film shows:\\r\\nImpression:\\r\\n-Bilateral lung infiltrations.\\r\\n-Suspect right lower lung patch. \\r\\n Blunting right CP angle. \\r\\n-Tortuous atherosclerotic aorta. \\r\\n-Scoliosis, DJD and osteoporosis of spine. \\r\\n Compression fracture of T12.\\r\\n Old fracture of left ribs.\\r\\n-S/P fixation in L-spine.  \\r\\n-S/P tracheostomy and NG tube.   \\r\\n']\n",
                        "\n",
                        "Names: ['NLP_CHEST_002']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest PA view shows: \\r\\n\\r\\nPartial atelectasis at left lower lung field. \\r\\nLeft pleural effusion.\\r\\n\\r\\nBorderline heart size. \\r\\nAtherosclerotic change of aortic knob. \\r\\n\\r\\nS/P port-A implantation via left subclavian vein. \\r\\nIntraperitoneal port catheter.\\r\\nSurgical clips at RUQ of abdomen.\\r\\n<|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest PA view shows: \\r\\n\\r\\nPartial atelectasis at left lower lung field. \\r\\nLeft pleural effusion.\\r\\n\\r\\nBorderline heart size. \\r\\nAtherosclerotic change of aortic knob. \\r\\n\\r\\nS/P port-A implantation via left subclavian vein. \\r\\nIntraperitoneal port catheter.\\r\\nSurgical clips at RUQ of abdomen.\\r\\n']\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluting Epoch: 1:  20%|██        | 2/10 [00:00<00:01,  5.77it/s, loss=5.17]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  30%|███       | 3/10 [00:00<00:01,  6.57it/s, loss=4.64]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  40%|████      | 4/10 [00:00<00:00,  6.92it/s, loss=4.64]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_004']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest PA view show: \\r\\nImpression:\\r\\n-S/P RLL wedge resection.\\u3000 \\r\\n-Bilateral lungs metastasis.\\r\\n-Left lower lung subsegmental atelectasis. \\r\\n-Increased infiltrations in both lungs.\\r\\n-Blunting right CP angle. \\r\\n-Tortuous atherosclerotic aorta.\\r\\n-Scoliosis, DJD and osteoporosis of spine. \\r\\n-Compression fracture of L1.<|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest PA view show: \\r\\nImpression:\\r\\n-S/P RLL wedge resection.\\u3000 \\r\\n-Bilateral lungs metastasis.\\r\\n-Left lower lung subsegmental atelectasis. \\r\\n-Increased infiltrations in both lungs.\\r\\n-Blunting right CP angle. \\r\\n-Tortuous atherosclerotic aorta.\\r\\n-Scoliosis, DJD and osteoporosis of spine. \\r\\n-Compression fracture of L1.']\n",
                        "\n",
                        "Names: ['NLP_CHEST_031']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest PA view:\\r\\nImpression:\\r\\n-Increased both lung markings. \\r\\n-Compatible with right lung nodules.\\r\\n-Fibrotic lesion in left upper lung.\\r\\n-Normal heart size. Atherosclerotic aorta. \\r\\n-Suspect right pleural effusion.\\r\\n-Spondylosis. R/O osteoporosis. \\r\\n-Compatible with multiple bony metastases.\\r\\n-S/P NG and endotracheal tube.\\r\\n-S/P Lt subclavian Port-A-cath. <|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest PA view:\\r\\nImpression:\\r\\n-Increased both lung markings. \\r\\n-Compatible with right lung nodules.\\r\\n-Fibrotic lesion in left upper lung.\\r\\n-Normal heart size. Atherosclerotic aorta. \\r\\n-Suspect right pleural effusion.\\r\\n-Spondylosis. R/O osteoporosis. \\r\\n-Compatible with multiple bony metastases.\\r\\n-S/P NG and endotracheal tube.\\r\\n-S/P Lt subclavian Port-A-cath. ']\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluting Epoch: 1:  40%|████      | 4/10 [00:00<00:00,  6.92it/s, loss=4.97]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  50%|█████     | 5/10 [00:00<00:00,  6.87it/s, loss=5.65]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_057']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest plain film shows:\\r\\nImpression:\\r\\n-Increased infiltrations in both lungs.\\r\\n-Tortuous atherosclerotic dilated aorta.\\r\\n-Normal heart size. \\r\\n-DJD of spine. \\r\\n Old fracture of right ribs.\\r\\n-Increased both lung markings. \\r\\n S/P Lt jugular CVC insertion. \\r\\n S/P NG and endotracheal tube.\\r\\n-Susp. Lt pneumothorax. \\r\\n Suspect pneumomediastinum. \\r\\n Subcutaneous emphysema in bilateral neck.  \\r\\n-S/P bilateral chest tube insertion. <|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest plain film shows:\\r\\nImpression:\\r\\n-Increased infiltrations in both lungs.\\r\\n-Tortuous atherosclerotic dilated aorta.\\r\\n-Normal heart size. \\r\\n-DJD of spine. \\r\\n Old fracture of right ribs.\\r\\n-Increased both lung markings. \\r\\n S/P Lt jugular CVC insertion. \\r\\n S/P NG and endotracheal tube.\\r\\n-Susp. Lt pneumothorax. \\r\\n Suspect pneumomediastinum. \\r\\n Subcutaneous emphysema in bilateral neck.  \\r\\n-S/P bilateral chest tube insertion. ']\n",
                        "\n",
                        "Names: ['NLP_CHEST_059']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Supine chest AP view shows: \\r\\n\\r\\nPigtail catheter at right lower chest.\\r\\nDecreased amount of right pleural effusion.\\r\\nAir in the right lower pleural space. Poor lung expansion.\\r\\nMild subcutaneous emphysema at right chest wall.\\r\\n\\r\\nRight pleural thickening.\\r\\nIll-defined masses at right perihilar region.\\r\\n\\r\\nNormal heart size. \\r\\n\\nLungs in the right lower chest.<|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Supine chest AP view shows: \\r\\n\\r\\nPigtail catheter at right lower chest.\\r\\nDecreased amount of right pleural effusion.\\r\\nAir in the right lower pleural space. Poor lung expansion.\\r\\nMild subcutaneous emphysema at right chest wall.\\r\\n\\r\\nRight pleural thickening.\\r\\nIll-defined masses at right perihilar region.\\r\\n\\r\\nNormal heart size. \\r\\n']\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluting Epoch: 1:  60%|██████    | 6/10 [00:01<00:00,  6.37it/s, loss=4.79]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  70%|███████   | 7/10 [00:01<00:00,  6.79it/s, loss=4.92]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_027']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest PA View:\\r\\nImpression: \\r\\n> Cardiomegaly with bilateral pulmonary congestion.\\r\\n> Postinflammatory fibrosis in both upper lungs.\\r\\n> Atherosclerosis of aorta.\\r\\n> Old fractures of left 5th and 6th ribs.\\r\\n> R/O osteoporosis.\\r\\n> Spondylosis of thoracolumbar spine.\\r\\n> S/P abdominal operation in RUQ.<|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest PA View:\\r\\nImpression: \\r\\n> Cardiomegaly with bilateral pulmonary congestion.\\r\\n> Postinflammatory fibrosis in both upper lungs.\\r\\n> Atherosclerosis of aorta.\\r\\n> Old fractures of left 5th and 6th ribs.\\r\\n> R/O osteoporosis.\\r\\n> Spondylosis of thoracolumbar spine.\\r\\n> S/P abdominal operation in RUQ.']\n",
                        "\n",
                        "Names: ['NLP_CHEST_085']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest X ray: \\r\\n\\r\\n- Right pneumothorax with pleural effusion, status post drainge \\r\\n  tube placement.\\r\\n- Extensive subcutaneous emphysema from neck to right side \\r\\n  thoracic cage.\\r\\n- Increased right hilar opacity.\\r\\n- Atherosclerosis and tortuous aorta. \\r\\n- Obscured bilateral costophrenic angles. \\r\\n- Spondylosis and mild scoliosis of thoracolumbar spine. \\r\\n- OA of right glenohumeral joint.\\r\\n- Generalized osteopenia. \\r\\n- Osteoporosis. <|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest X ray: \\r\\n\\r\\n- Right pneumothorax with pleural effusion, status post drainge \\r\\n  tube placement.\\r\\n- Extensive subcutaneous emphysema from neck to right side \\r\\n  thoracic cage.\\r\\n- Increased right hilar opacity.\\r\\n- Atherosclerosis and tortuous aorta. \\r\\n- Obscured bilateral costophrenic angles. \\r\\n- Spondylosis and mild scoliosis of thoracolumbar spine. \\r\\n- OA of right glenohumeral joint.\\r\\n- Generalized osteopenia. \\r\\n']\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluting Epoch: 1:  80%|████████  | 8/10 [00:01<00:00,  6.20it/s, loss=5.28]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
                        "Evaluting Epoch: 1:  90%|█████████ | 9/10 [00:01<00:00,  5.94it/s, loss=5.99]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_011']\n",
                        "Predictions: [\"Please generate a report based on the given chest X-ray image. <|endoftext|> Chest AP view showed:\\r\\n1.s/p sternotomy and CABG.\\r\\n  Enlarged heart size with tortuous aorta.\\r\\n2.R't middle and lower lung faint patches.\\r\\n  L't lower lung consolidation.\\r\\n  L't pleural effusion.\\r\\n3.No mediastinum widening.\\r\\n4.s/p endotracheal tube and NG intubation.\\r\\n  L't lower lung and L't lower lung.<|endoftext|>\"]\n",
                        "Labels: [\"Please generate a report based on the given chest X-ray image.<|endoftext|> Chest AP view showed:\\r\\n1.s/p sternotomy and CABG.\\r\\n  Enlarged heart size with tortuous aorta.\\r\\n2.R't middle and lower lung faint patches.\\r\\n  L't lower lung consolidation.\\r\\n  L't pleural effusion.\\r\\n3.No mediastinum widening.\\r\\n4.s/p endotracheal tube and NG intubation.\\r\\n\"]\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Evaluting Epoch: 1: 100%|██████████| 10/10 [00:01<00:00,  6.08it/s, loss=5.99]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Names: ['NLP_CHEST_015']\n",
                        "Predictions: ['Please generate a report based on the given chest X-ray image. <|endoftext|> Chest X ray: \\r\\n\\r\\n- No obvious lung mass nor consolidation patch.\\r\\n- Normal heart size.\\r\\n- No pleural effusion. \\U000fe309\\n- No pleural effusion. \\U000fe309<|endoftext|>']\n",
                        "Labels: ['Please generate a report based on the given chest X-ray image.<|endoftext|> Chest X ray: \\r\\n\\r\\n- No obvious lung mass nor consolidation patch.\\r\\n- Normal heart size.\\r\\n- No pleural effusion. ']\n",
                        "\n",
                        "Rouge-2 score on epoch 0: ({'Rouge-L-P': 0.6607337529932065, 'Rouge-L-R': 0.9952925507485995, 'Rouge-L-F': 0.9952925507485995, 'Rouge-2-P': 0.8235696003058185, 'Rouge-2-R': 0.927234826449486, 'Rouge-2-F': 0.927234826449486}, 5.210005569458008)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "for epoch in range(epochs):\n",
                "    lm.train()\n",
                "\n",
                "    pbar = tqdm(train_dataloader)\n",
                "    pbar.set_description(f\"Training Epoch [{epoch + 1} / {epochs}]\")\n",
                "\n",
                "    for _, images, inputs, labels, attention_mask in pbar:\n",
                "        optimizer.zero_grad()\n",
                "        loss = lm(\n",
                "            input_ids=inputs,\n",
                "            attention_mask=attention_mask,\n",
                "            encoder_hidden_states=images,\n",
                "            labels=labels\n",
                "        ).loss\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        pbar.set_postfix(loss=loss.item())\n",
                "\n",
                "    torch.save(lm, f\"outputs/checkpoint_{epoch}.pt\")\n",
                "\n",
                "    print(f\"Rouge-2 score on epoch {epoch}:\", evaluate(lm=lm, epoch=epoch))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "GAI",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
